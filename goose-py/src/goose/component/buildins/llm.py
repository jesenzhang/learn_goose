import json
import re
import logging
import resource
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field, ConfigDict

from goose.component.base import Component
from goose.component.registry import register_component
from goose.resources.tool import ToolDefinitionRegistry, ToolSourceType, ToolDefinition
from goose.workflow.context import WorkflowContext
from goose.utils.template import TemplateRenderer
from goose.providers import ProviderFactory
from goose.conversation import Message

logger = logging.getLogger("goose.component.llm")

# ==========================================
# é…ç½®æ¨¡å‹ (Schema Definition)
# ==========================================

class OutputDefinition(BaseModel):
    name: str
    type: str = "string" # string, number, boolean, array, object
    description: Optional[str] = None

class LLMConfig(BaseModel):
    # --- æ¨¡å‹é…ç½® ---
    model: str = Field(..., description="æ¨¡å‹åç§° (e.g. gpt-4o)")
    base_url: Optional[str] = Field(None, description="API Base URL")
    api_key: Optional[str] = Field(None, description="API Key")
    
    # --- æç¤ºè¯ ---
    prompt: str = Field(..., description="ç”¨æˆ·æç¤ºè¯ (æ”¯æŒ {{var}})")
    system_prompt: str = Field("", description="ç³»ç»Ÿæç¤ºè¯ (æ”¯æŒ {{var}})")
    
    # --- å·¥å…·ä¸å‚æ•° ---
    tools: List[str] = Field(default_factory=list, description="æŒ‚è½½çš„å·¥å…· ID åˆ—è¡¨")
    
    # --- è¾“å‡ºæ§åˆ¶ ---
    response_format: str = Field("text", description="è¾“å‡ºæ¨¡å¼: text æˆ– json_object")
    output_definitions: List[OutputDefinition] = Field(default_factory=list, description="è¾“å‡ºå˜é‡å®šä¹‰")
    
    # --- é«˜çº§å‚æ•° ---
    temperature: float = 0.7
    max_tokens: int = 4096
    max_iterations: int = 5  # ReAct æœ€å¤§å¾ªç¯æ¬¡æ•°
    
    model_config = ConfigDict(extra='allow')

# ==========================================
# LLM Component Implementation
# ==========================================

@register_component
class LLMComponent(Component):
    name = "llm"
    label = "å¤§è¯­è¨€æ¨¡å‹"
    description = "æ‰§è¡Œå¯¹è¯ã€å·¥å…·è°ƒç”¨åŠç»“æ„åŒ–è¾“å‡º"
    group = "AI"
    icon = "cpu"
    config_model = LLMConfig

    async def execute(self, inputs: Dict[str, Any],config: LLMConfig) -> Dict[str, Any]:
        """
        æ ¸å¿ƒæ‰§è¡Œé€»è¾‘ï¼š
        1. å‡†å¤‡å·¥å…·å’Œæ¨¡å‹ã€‚
        2. æ¸²æŸ“ Promptã€‚
        3. æ³¨å…¥ JSON Schema (å¦‚æœéœ€è¦)ã€‚
        4. æ‰§è¡Œ ReAct å¾ªç¯ (Chat -> Tool -> Chat)ã€‚
        5. è§£æè¾“å‡ºã€‚
        """
        
        # 1. [å‡†å¤‡] å·¥å…·å®šä¹‰
        tool_defs = []
        openai_tools = []
        
        if config.tools:
            for tool_id in config.tools:
                # ä» Goose çš„ ToolRegistry è·å–
                t_def = ToolDefinitionRegistry.get(tool_id)
                if t_def:
                    tool_defs.append(t_def)
                    # è½¬æ¢ä¸º OpenAI æ ¼å¼ (å‡è®¾ ToolDefinition å®ç°äº† to_openai_format)
                    # å¦‚æœæ²¡æœ‰å®ç°ï¼Œè¿™é‡Œéœ€è¦æ‰‹åŠ¨è½¬æ¢ï¼Œä¸‹æ–‡ä¼šæä¾› Helper
                    openai_tools.append(self._to_openai_tool(t_def))
                else:
                    logger.warning(f"Tool not found: {tool_id}")

        # 2. [å‡†å¤‡] æ¨¡å‹ Provider
        # ä¼˜å…ˆä½¿ç”¨ config ä¸­çš„é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»ç³»ç»Ÿé»˜è®¤é…ç½®è·å–
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæ¯æ¬¡åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ Provider å®ä¾‹
        provider_config = {
            "model_name": config.model,
            "api_key": config.api_key or "default", # å®é™…åº”ä» ENV æˆ– KeyManager è·å–
            "base_url": config.base_url,
            "temperature": config.temperature,
            "max_tokens": config.max_tokens
        }
        # ç®€å•å·¥å‚æ¨¡å¼åˆ›å»º Provider (OpenAI Compatible)
        provider = ProviderFactory.create("openai", provider_config)

        # 3. [æ¸²æŸ“] Prompt
        system_instruction = config.system_prompt
        
        # å¦‚æœæ˜¯ JSON æ¨¡å¼ï¼Œæ„å»º Schema å¹¶æ³¨å…¥ System Prompt
        if config.response_format == "json_object" and config.output_definitions:
            try:
                target_schema = self._build_json_schema(config.output_definitions)
                json_instruction = f"""
                \n\n## Output Requirement
                You MUST respond with a valid JSON object strictly adhering to the following Schema.
                Output raw JSON only. Do not use Markdown blocks.
                
                JSON Schema:
                {json.dumps(target_schema, indent=2)}
                """
                system_instruction += json_instruction
            except Exception as e:
                logger.warning(f"Failed to build JSON schema: {e}")

        # ä½¿ç”¨ TemplateRenderer æ¸²æŸ“å˜é‡
        system_content = TemplateRenderer.render(system_instruction, inputs)
        user_content = TemplateRenderer.render(config.prompt, inputs)
        
        messages = []
        if system_content:
            messages.append(Message.system(system_content))
        messages.append(Message.user(user_content))

        # 4. [æ‰§è¡Œ] ReAct Loop
        current_iter = 0
        final_response_content = ""
        final_reasoning_content = ""
        
        while current_iter < config.max_iterations:
            current_iter += 1
            
            # --- è°ƒç”¨ LLM ---
            # æ³¨æ„ï¼šGoose çš„ Provider æ¥å£é€šå¸¸è¿”å› Message å¯¹è±¡
            response_msg = await provider.generate(messages, tools=openai_tools if openai_tools else None)
            
            # ç´¯ç§¯æ¨ç†å†…å®¹ (DeepSeek/O1)
            if response_msg.reasoning_content:
                final_reasoning_content += response_msg.reasoning_content
            
            # è¿½åŠ åˆ°å†å²
            messages.append(response_msg)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if not response_msg.tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡ç»“æŸ
                final_response_content = response_msg.content
                break
            
            # --- æ‰§è¡Œå·¥å…· ---
            logger.info(f"ğŸ”§ Tool Calls detected: {len(response_msg.tool_calls)}")
            
            for tool_call in response_msg.tool_calls:
                call_id = tool_call.id
                func_name = tool_call.function.name
                args_str = tool_call.function.arguments
                
                tool_result_content = ""
                
                # æŸ¥æ‰¾åŒ¹é…çš„æœ¬åœ°å·¥å…·å®šä¹‰
                target_tool = next((t for t in tool_defs if t.name == func_name), None)
                
                if target_tool:
                    try:
                        args = json.loads(args_str)
                        # æ‰§è¡Œå·¥å…·
                        # LLMComponent ä½œä¸ºä¸€ä¸ª Componentï¼Œè°ƒç”¨å·¥å…·æ—¶éœ€è¦ä¼ å…¥ context
                        # å¦‚æœå·¥å…·æ˜¯ Builtin å‡½æ•°
                        if target_tool.source_type == ToolSourceType.BUILTIN:
                            # æ³¨å…¥ context å¦‚æœéœ€è¦ï¼Œæˆ–ç›´æ¥è°ƒç”¨
                            # è¿™é‡Œå¤ç”¨ PluginComponent çš„é€»è¾‘ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨ func
                            if getattr(target_tool, 'func', None):
                                res = target_tool.func(**args)
                                if hasattr(res, '__await__'): # Async check
                                    res = await res
                                tool_result_content = json.dumps(res, ensure_ascii=False) if isinstance(res, (dict, list)) else str(res)
                        
                        # å¦‚æœæ˜¯ Plugin (HTTP)ï¼Œè¿™é‡Œæš‚ç•¥ï¼Œå»ºè®®å¤ç”¨ PluginComponent çš„é€»è¾‘
                        
                    except Exception as e:
                        tool_result_content = f"Error executing tool: {str(e)}"
                else:
                    tool_result_content = f"Error: Tool {func_name} not found locally."

                # å°†å·¥å…·ç»“æœå›å¡«ç»™ LLM
                messages.append(Message.tool(tool_result_content, tool_call_id=call_id))

        # 5. [è§£æ] ç»“æœå¤„ç†
        final_output = {}
        
        # æ¨¡å¼ A: JSON Object
        if config.response_format == "json_object":
            try:
                cleaned_json = self._clean_json_markdown(final_response_content)
                parsed_data = json.loads(cleaned_json)
                final_output = parsed_data
            except Exception as e:
                logger.error(f"JSON Parse Error: {e}")
                final_output = {"output": final_response_content, "_error": "JSON parse failed"}
        
        # æ¨¡å¼ B: Text
        else:
            # æ™ºèƒ½æ˜ å°„ï¼šå¦‚æœå‰ç«¯å®šä¹‰äº†è¾“å‡ºå˜é‡åï¼Œå°è¯•å°†ç»“æœèµ‹ç»™ç¬¬ä¸€ä¸ªå˜é‡
            output_key = "output"
            if config.output_definitions:
                valid_defs = [d for d in config.output_definitions if d.name not in ["reasoning_content"]]
                if valid_defs:
                    output_key = valid_defs[0].name
            
            final_output[output_key] = final_response_content

        # æ³¨å…¥æ¨ç†è¿‡ç¨‹ (å¯é€‰)
        if final_reasoning_content:
            final_output["reasoning_content"] = final_reasoning_content

        return final_output

    # --- Helpers ---

    def _build_json_schema(self, output_defs: List[OutputDefinition]) -> Dict[str, Any]:
        """æ„å»º JSON Schema"""
        if not output_defs: return {}
        
        properties = {}
        required = []
        
        for item in output_defs:
            schema_type = item.type if item.type != "json" else "object"
            prop = {"type": schema_type}
            
            if schema_type == "array":
                prop["items"] = {"type": "string"}
            if schema_type == "object":
                prop["additionalProperties"] = True
            if item.description:
                prop["description"] = item.description
                
            properties[item.name] = prop
            required.append(item.name)
            
        return {
            "type": "object",
            "properties": properties,
            "required": required,
            "additionalProperties": False
        }

    def _clean_json_markdown(self, text: str) -> str:
        """æ¸…æ´— Markdown æ ¼å¼çš„ JSON"""
        text = text.strip()
        pattern = r"^```(?:json)?\s*(\{.*?\})\s*```$"
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            return match.group(1)
        # å¯å‘å¼æŸ¥æ‰¾å¤§æ‹¬å·
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1:
            return text[start : end + 1]
        return text

    def _to_openai_tool(self, tool_def: ToolDefinition) -> Dict:
        """ç®€å•çš„å·¥å…·å®šä¹‰è½¬æ¢å™¨"""
        # å¦‚æœ ToolDefinition ä¸­å·²ç»ç¼“å­˜äº† openai schema æœ€å¥½
        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„ mock è½¬æ¢
        return {
            "type": "function",
            "function": {
                "name": tool_def.name,
                "description": tool_def.description or "",
                "parameters": tool_def.args_schema or {"type": "object", "properties": {}}
            }
        }