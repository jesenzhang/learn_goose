import logging
import asyncio
from typing import Any, Optional, Dict, List, TYPE_CHECKING

# --- Core Dependencies ---
from goose.workflow.protocol import ControlSignal
from goose.workflow.graph import Graph
from goose.workflow.context import WorkflowContext
from goose.events import SystemEvents
from goose.workflow.events import WorkflowEventType
from goose.workflow.persistence import WorkflowState, WorkflowCheckpointer
from goose.workflow.repository import WorkflowRepository, register_workflow_schemas

# --- Runtime Dependencies ---
from goose.globals import get_streamer_factory, get_runtime
from goose.workflow.hooks import WorkflowHook

if TYPE_CHECKING:
    from goose.resources.manager import ResourceManager

logger = logging.getLogger("goose.workflow.scheduler")

class WorkflowScheduler:
    """
    [Core] å·¥ä½œæµè°ƒåº¦å¼•æ“ã€‚
    è´Ÿè´£å›¾çš„éå†ã€èŠ‚ç‚¹æ‰§è¡Œã€çŠ¶æ€ç®¡ç†ã€æŒä¹…åŒ–ã€‚
    """
    
    def __init__(self, 
                 checkpointer: Optional[WorkflowCheckpointer] = None,
                 hooks: List[WorkflowHook] = None # [æ–°å¢] æ¥æ”¶é’©å­åˆ—è¡¨
                 ):
        # ç¡®ä¿æ•°æ®åº“ Schema å·²å°±ç»ª
        register_workflow_schemas()
        # é»˜è®¤ä½¿ç”¨ SQL Repository
        self._default_checkpointer = checkpointer or WorkflowRepository()
        self.hooks = hooks or [] # [æ–°å¢]

    # --- è¾…åŠ©æ–¹æ³•ï¼šæ‰¹é‡æ‰§è¡Œé’©å­ ---
    async def _trigger_hooks(self, method_name: str, *args, **kwargs):
        """å®‰å…¨åœ°æ‰§è¡Œæ‰€æœ‰é’©å­"""
        for hook in self.hooks:
            try:
                # è·å–å¯¹åº”çš„æ–¹æ³•
                func = getattr(hook, method_name, None)
                if func:
                    await func(*args, **kwargs)
            except Exception as e:
                # é’©å­æŠ¥é”™ä¸åº”é˜»æ–­ä¸»æµç¨‹ï¼Œæ‰“å°æ—¥å¿—å³å¯
                logger.error(f"ğŸª Hook error in {method_name}: {e}", exc_info=True)
                
    async def run(
        self, 
        graph: Graph, 
        inputs: Any, 
        run_id: str = None, 
        resume: bool = False,
        parent_ctx: WorkflowContext = None,
        resource_manager: Optional['ResourceManager'] = None,
        target_node_id: Optional[str] = None
    ) -> Any:
        """
        æ‰§è¡Œå·¥ä½œæµã€‚
        :return: æœ€ç»ˆæ‰§è¡Œç»“æœ (Final Output Dict)
        """
        
        # ==========================================
        # 1. åŸºç¡€è®¾æ–½å‡†å¤‡
        # ==========================================
        # 1.1 æ ¡éªŒå›¾
        entry_point_id = graph.entry_point
        if not entry_point_id:
             raise ValueError("Graph has no entry point!")
             
        runtime = get_runtime()
        # 1. çº¯ç²¹çš„ ID ç”Ÿæˆ (ä¸æ¶‰åŠæ•°æ®åº“)
        if not run_id:
            import uuid
            run_id = uuid.uuid4().hex
            logger.info(f"ğŸ†” Generated ephemeral run_id: {run_id}")
            
        # # 1.2 å‡†å¤‡ Session
        # if not run_id:
        #     # è‡ªåŠ¨åˆ›å»ºæ¨¡å¼
        #     session = await SessionManager.create_workflow_session(name="Auto Workflow Run")
        #     run_id = session.id
        #     logger.info(f"ğŸ†• Auto-created Workflow Session: {run_id}")
        # else:
        #     # æ¢å¤/æŒ‡å®šæ¨¡å¼
        #    # [FIX] æŒ‡å®š ID æ¨¡å¼ï¼šç¡®ä¿ Session å­˜åœ¨
        #     try:
        #         # å°è¯•è·å– Sessionï¼Œå¦‚æœä¸å­˜åœ¨é€šå¸¸ä¼šæŠ›å‡ºé”™è¯¯ (å–å†³äºä½ çš„ SessionManager å®ç°)
        #         # æˆ–è€…æŸ¥åº“è¿”å› None
        #         session = await SessionManager.get_session(run_id)
        #         if not session:
        #             raise ValueError("Session not found")
        #         logger.info(f"ğŸ”„ Using existing session {run_id}")
        #     except Exception:
        #         # å¦‚æœ Session ä¸å­˜åœ¨ï¼Œå¿…é¡»åˆ›å»ºå®ƒï¼Œå¦åˆ™åç»­çš„å¤–é”®çº¦æŸä¼šæŠ¥é”™ï¼
        #         logger.info(f"ğŸ†• Registering new session for provided ID: {run_id}")
        #         await SessionManager.create_session(
        #             session_id=run_id, 
        #             name=f"Run {run_id[:8]}",
        #             session_type=SessionType.WORKFLOW
        #         )
        # 1.3 è·å– Streamer (Event Producer)
        streamer = runtime.streamer_factory.create(run_id)
        
        # 1.4 å…œåº• Resource Manager
        if resource_manager is None:
            logger.warning("âš ï¸ No ResourceManager provided. Creating default (system-only).")
            resource_manager = runtime.create_resource_manager(user_id=None)

        # ==========================================
        # 2. ä¸Šä¸‹æ–‡æ„å»ºä¸æ³¨å…¥
        # ==========================================
        
        # åˆå§‹å˜é‡ (ç”¨äº ValueResolver)
        initial_vars = inputs if isinstance(inputs, dict) else {"input": inputs}
        
        context = WorkflowContext(
            session_id=run_id,
            parent_run_id=parent_ctx.run_id if parent_ctx else None,
            variables=initial_vars
        )
        
        # å˜é‡ç»§æ‰¿
        if parent_ctx:
            context.variables.update(parent_ctx.variables)
            
        # [Core] ä¾èµ–æ³¨å…¥
        context.set_services(
            resources=resource_manager,
            streamer=streamer,
            executor=self
        )

        # ==========================================
        # 3. çŠ¶æ€æ¢å¤ä¸é˜Ÿåˆ—åˆå§‹åŒ–
        # ==========================================
        queue = []
        
        if resume:
            state = await self._default_checkpointer.load_checkpoint(run_id)
            if state and state.status not in ["completed", "failed", "cancelled"]:
                logger.info(f"ğŸ“¥ Resuming run {run_id} from checkpoint.")
                context.node_outputs = state.context_data # æ¢å¤å†…å­˜
                if state.execution_queue:
                    queue.extend(state.execution_queue)
            else:
                logger.warning(f"âš ï¸ Cannot resume run {run_id}. Restarting.")

        # åˆå§‹åŒ–é˜Ÿåˆ—
        if not queue:
            queue.append(entry_point_id)

        # ==========================================
        # 4. æ‰§è¡Œä¸»å¾ªç¯
        # ==========================================
        
        # [Event] Workflow Started
        
        await self._trigger_hooks("on_workflow_start", run_id, inputs, context)
        await streamer.emit(SystemEvents.WORKFLOW_STARTED, inputs)
        
        
        try:
            while queue:
                current_node_id = queue.pop(0)

                # --- A. æŒ‚èµ·æ£€æŸ¥ ---
                if current_node_id == "__SUSPEND__":
                    logger.info(f"â¸ï¸ Workflow {run_id} suspended.")
                    await self._save_state(run_id, queue, context, "suspended")
                    return None

                # --- B. è·å–èŠ‚ç‚¹æ•°æ® ---
                node = graph.get_node(current_node_id)
                if not node:
                    logger.error(f"âŒ Node {current_node_id} not found.")
                    continue
                
                
                # --- C. å‡†å¤‡ç»„ä»¶å‚æ•° ---
                
                # [Input Logic]
                # 1. Entry Point: æ¥æ”¶å¤–éƒ¨çœŸå®è¾“å…¥ (inputs)
                # 2. Normal Node: æ¥æ”¶é…ç½®æ˜ å°„ (node.inputs)
                if current_node_id == entry_point_id:
                    # å½’ä¸€åŒ–è¾“å…¥ä¸ºå­—å…¸
                    if isinstance(inputs, dict):
                        invocation_inputs = inputs
                    else:
                        invocation_inputs = {"inputs": inputs}
                else:
                    invocation_inputs = node.inputs

                # --- D. [Core] è°ƒç”¨æ— çŠ¶æ€ç»„ä»¶ ---
                try:
                    # æ˜¾å¼ä¼ é€’: è¾“å…¥, é™æ€é…ç½®, ä¸Šä¸‹æ–‡
                    invocation_config = node.config.copy()
                    invocation_config["id"] = current_node_id
                    
                    await self._trigger_hooks("on_node_start", run_id, node, invocation_inputs, context)
                    # [Event] Node Started
                    await streamer.emit(
                        SystemEvents.NODE_STARTED, 
                        data={"node_type": node.component.__class__.__name__}, 
                        producer_id=current_node_id
                    )


                    output = await node.component.invoke(
                        inputs=invocation_inputs,
                        config=invocation_config,
                        context=context
                    )
                    
                except Exception as e:
                    logger.error(f"âŒ Node {current_node_id} execution failed: {e}", exc_info=True)
                    await streamer.emit(SystemEvents.NODE_ERROR, str(e), producer_id=current_node_id)
                    raise e

                # --- E. æ›´æ–°ä¸Šä¸‹æ–‡ ---
                if output is not None:
                    context.set_node_output(current_node_id, output)

                await self._trigger_hooks("on_node_end", run_id, node, output, context)
                # [Event] Node Finished
                await streamer.emit(
                    SystemEvents.NODE_FINISHED, 
                    data=output, 
                    producer_id=current_node_id
                )
                # --- F. è·¯ç”±ä¸æ§åˆ¶æµ ---
                
                # 1. ä¿¡å·å¤„ç†
                if isinstance(output, dict) and ControlSignal.SIGNAL_KEY in output:
                    signal = output[ControlSignal.SIGNAL_KEY]
                    logger.info(f"ğŸš¦ Signal: {signal}")
                    continue 
                
                # ==========================================
                # 1. æ‹“æ‰‘éå† (å…ˆè®¡ç®—ä¸‹ä¸€æ­¥å»å“ªï¼Œç¡®ä¿ Queue é‡Œæœ‰è´§)
                # ==========================================
                outgoing_edges = graph.get_outgoing_edges(current_node_id)
                next_nodes = []
                
                active_handle = output.get(ControlSignal.ACTIVE_HANDLE) if isinstance(output, dict) else None
                
                for edge in outgoing_edges:
                    if active_handle:
                        if edge.source_handle == active_handle:
                            next_nodes.append(edge.target)
                    elif edge.source_handle is None:
                        next_nodes.append(edge.target)

                # å…¥é˜Ÿ (ç®€å•å»é‡)
                for nid in next_nodes:
                    if nid not in queue: 
                        queue.append(nid)

                # ==========================================
                # 2. ğŸ¯ æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡èŠ‚ç‚¹ (ç°åœ¨æ£€æŸ¥ï¼Œæ”¯æŒ Resume)
                # ==========================================
                if target_node_id and current_node_id == target_node_id:
                    logger.info(f"ğŸ¯ Reached target node {target_node_id}. Stopping execution.")
                    
                    # 1. æ­¤æ—¶ output å·²ç»æ˜¯å½“å‰èŠ‚ç‚¹çš„è¾“å‡º
                    # 2. æˆ‘ä»¬ä¾ç„¶éœ€è¦ä¿å­˜çŠ¶æ€ï¼Œä»¥ä¾¿ç”¨æˆ·æŸ¥çœ‹ Context æˆ–æœªæ¥æ”¯æŒâ€œä»æ­¤å¤„ç»§ç»­â€
                    #    æ³¨æ„ï¼šæ­¤æ—¶ queue é‡Œå¯èƒ½è¿˜æœ‰å¹¶è¡Œåˆ†æ”¯çš„èŠ‚ç‚¹ï¼Œæˆ–è€…æˆ‘ä»¬è¿˜æœªè®¡ç®— outgoing_edges
                    #    ä¸ºäº†æ”¯æŒâ€œæš‚åœâ€ï¼Œå»ºè®®ä¿å­˜å½“å‰çŠ¶æ€ (Status: stopped/suspended)
                    
                    await self._save_state(run_id, queue, context, status="stopped")
                    
                    # 3. å‘é€å®Œæˆäº‹ä»¶ (æˆ–è€…ä¸“é—¨çš„ Stopped äº‹ä»¶)
                    # è¿™é‡Œå‘é€ COMPLETED å¯èƒ½ä¸å¤ªå‡†ç¡®ï¼Œå»ºè®®å‰ç«¯æ ¹æ® status åˆ¤æ–­
                    await self._trigger_hooks("on_workflow_end", run_id, output, context)
                    await streamer.emit(SystemEvents.WORKFLOW_COMPLETED, output) 
                    
                    return output
                
                
                # --- G. æŒä¹…åŒ– (Checkpoint) ---
                status_to_save = "running" if queue else "completed"
                await self._save_state(run_id, queue, context, status_to_save)

            # ==========================================
            # 5. ç»“æŸå¤„ç†
            # ==========================================
            logger.info(f"ğŸ Workflow {run_id} Completed.")
            
            # æå–æœ€ç»ˆç»“æœ (Heuristic: å–æœ€åä¸€ä¸ªèŠ‚ç‚¹çš„è¾“å‡º)
            # å¦‚æœ Context é‡Œæœ‰ä¸“é—¨æ ‡è®°çš„ outputs ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæå–
            final_output = context.node_outputs.get(current_node_id, {})
            
            
            await self._trigger_hooks("on_workflow_end", run_id, final_output, context)
            await streamer.emit(SystemEvents.WORKFLOW_COMPLETED, final_output)
            
            return final_output

        except Exception as e:
            logger.error(f"ğŸ’¥ Workflow {run_id} Crashed: {e}")
            await streamer.emit(SystemEvents.WORKFLOW_FAILED, str(e))
            await self._trigger_hooks("on_workflow_error", run_id, e,context)
            # ä¿å­˜å¤±è´¥çŠ¶æ€
            retry_queue = [current_node_id] + queue
            await self._save_state(run_id, retry_queue, context, "failed")
            raise e

    # ==========================================
    # Helpers
    # ==========================================

    async def _save_state(self, run_id: str, queue: List[str], context: WorkflowContext, status: str):
        """æŒä¹…åŒ–çŠ¶æ€è¾…åŠ©æ–¹æ³•"""
        if self._default_checkpointer:
            state = WorkflowState(
                run_id=run_id,
                execution_queue=queue,
                context_data=context.node_outputs, 
                status=status
            )
            await self._default_checkpointer.save_checkpoint(state)

    async def run_to_completion(
        self, 
        inputs: Dict[str, Any], 
        parent_ctx: Optional[WorkflowContext] = None,
        graph: Graph = None # éœ€è¦ä¼ å…¥å­å›¾
    ) -> Dict[str, Any]:
        """
        [Helper] è¿è¡Œå­å›¾ç›´åˆ°ç»“æŸï¼Œå¹¶ç›´æ¥è¿”å›ç»“æœã€‚
        å› ä¸º run ç°åœ¨æ˜¯æ™®é€šçš„ awaitableï¼Œæ‰€ä»¥è¿™é‡Œç›´æ¥ await å³å¯ã€‚
        """
        if not graph:
            raise ValueError("Sub-workflow graph must be provided")

        # å­å·¥ä½œæµä½¿ç”¨çˆ¶çº§çš„èµ„æºç®¡ç†å™¨ (åŒç”¨æˆ·)ï¼Œä½†ç‹¬ç«‹çš„ run_id
        return await self.run(
            graph=graph,
            inputs=inputs,
            parent_ctx=parent_ctx,
            resource_manager=parent_ctx.resources if parent_ctx else None
        )