import asyncio
import json
import logging
import sys
import os
import uuid
from pathlib import Path
from typing import Dict, Any, List

from goose.workflow.converter import WorkflowConverter

# --- æ·»åŠ  src åˆ° python path ä»¥ä¾¿å¯¼å…¥ goose æ¨¡å— ---
sys.path.append(str(Path(__file__).parent.parent / "src"))

# --- Goose æ¨¡å—å¯¼å…¥ ---
from goose import workflow
from goose.config import SystemConfig
from goose.events import IStreamer
from goose.events.types import SystemEvents, Event
from goose.workflow.scheduler import WorkflowScheduler, Graph
from goose.resources.types import ResourceKind
from goose.system import boot, shutdown
from goose.globals import get_streamer_factory, get_runtime
from goose.adapter import AdapterManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("IntegrationTest")

# ==========================================
# 0. æµ‹è¯•æ•°æ®å‡†å¤‡ (Test Data Setup)
# ==========================================

TEST_JSON_PATH = Path(r"F:\Workspace\learn_goose\goose-py\tests\test.json")

def ensure_test_json_exists():
    """
    å¦‚æœæµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„ VueFlow æ ¼å¼ JSONã€‚
    åŒ…å«ï¼šå¼€å§‹èŠ‚ç‚¹ -> LLMèŠ‚ç‚¹ (å¼•ç”¨ç³»ç»Ÿèµ„æº) -> ç»“æŸèŠ‚ç‚¹
    """

    logger.info(f"Creating default test file at: {TEST_JSON_PATH}")
    TEST_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)

    
    with open(TEST_JSON_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    logger.info(f"Test file created successfully: {TEST_JSON_PATH}")

    adapter = AdapterManager.get_adapter('vueflow')
    return adapter.transform_workflow(data)

# ==========================================
# 3. æ¸²æŸ“å®¢æˆ·ç«¯ (Console Client)
# ==========================================

class ConsoleClient:
    """æ¨¡æ‹Ÿå‰ç«¯ SSE æ¥æ”¶ç«¯"""
    def __init__(self, run_id: str):
        self.run_id = run_id
        # é€šè¿‡å…¨å±€ Helper è·å–å·¥å‚
        self.factory = get_streamer_factory()

    async def connect(self, after_seq_id: int = -1, client_name: str = "Client"):
        streamer = self.factory.create(self.run_id)
        logger.info(f"ğŸ“¡ {client_name} connecting to stream (seq > {after_seq_id})...")
        
        buffer = ""
        
        async for event in streamer.listen(after_seq_id=after_seq_id):
            # å¤„ç† Token (ä¸æ¢è¡Œæ‰“å°)
            if event.type == SystemEvents.STREAM_TOKEN:
                sys.stdout.write(f"\033[96m{event.data}\033[0m")
                sys.stdout.flush()
                buffer += str(event.data)
            
            # å¤„ç†ç»“æ„åŒ–æ—¥å¿—
            elif event.type == SystemEvents.NODE_STARTED:
                print(f"\n[ğŸŸ¢ Node Start] {event.producer_id}")
            
            elif event.type == SystemEvents.NODE_FINISHED:
                print(f"\n[ğŸ”´ Node End] {event.producer_id}")
                
            elif event.type == "log":
                print(f"\n[ğŸ“ Log] {event.data}")
                
            elif event.type == SystemEvents.WORKFLOW_COMPLETED:
                print(f"\n\nâœ… {client_name} Received WORKFLOW_COMPLETED")
                break
                
            elif event.type == SystemEvents.WORKFLOW_FAILED:
                print(f"\nâŒ {client_name} Received WORKFLOW_FAILED: {event.data}")
                break

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================

async def main():
    # --- Step 0: å‡†å¤‡æ–‡ä»¶ ---
   
    
# --- Step 1: ç³»ç»Ÿå¯åŠ¨ (Boot) ---
    logger.info("âš¡ Booting System...")
    
    config = SystemConfig()
    # boot() ä¼šè´Ÿè´£åˆå§‹åŒ– Runtime, Persistence, Resources
    runtime = await boot(config)
    workflow = ensure_test_json_exists()
    # --- Step 2: åŠ è½½å›¾ ---
    logger.info(f"ğŸ“‚ Loading workflow from {TEST_JSON_PATH}...")
    try:
        converter = WorkflowConverter()
        graph = converter.convert(workflow)
        logger.info(f"   Graph loaded: {len(graph.nodes)} nodes configured.")
    except Exception as e:
        logger.error(f"Failed to load graph: {e}")
        return

    # --- Step 3: è¿è¡Œå·¥ä½œæµ (å®æ—¶) ---
    run_id = f"run_{uuid.uuid4().hex[:8]}"
    scheduler = WorkflowScheduler()
    client = ConsoleClient(run_id)
    
    logger.info(f"â–¶ï¸ Starting Execution [RunID: {run_id}]")
    
    # å¹¶è¡Œæ‰§è¡Œï¼šè°ƒåº¦å™¨è·‘ä»»åŠ¡ vs å®¢æˆ·ç«¯çœ‹ç›´æ’­
    await asyncio.gather(
        scheduler.run(graph, inputs={"query": "Manual Trigger"}, run_id=run_id),
        client.connect(client_name="Live_Viewer")
    )
    
    # --- Step 4: æµ‹è¯•æŒ‚èµ·ä¸æ¢å¤ (Backfill) ---
    logger.info("\n\nğŸ”„ Testing Resume / Backfill Capability...")
    logger.info("   Simulating a new client requesting full history...")
    
    # æ¨¡æ‹Ÿæ–°å®¢æˆ·ç«¯è¿æ¥ï¼Œè¯·æ±‚ seq_id > -1 (å³ä»å¤´å¼€å§‹)
    client_replay = ConsoleClient(run_id)
    await client_replay.connect(after_seq_id=-1, client_name="History_Viewer")
    
    # --- Step 5: éªŒè¯æ•°æ®ä¸€è‡´æ€§ ---
    logger.info("\nğŸ“Š Verifying Data Persistence...")
    # ç›´æ¥ä» EventStore æŸ¥åº“
    events = await runtime.event_store.get_events(run_id)
    logger.info(f"   Total events persisted in DB: {len(events)}")
    
    if len(events) == 0:
        logger.error("âŒ Persistence failed! No events found.")
        sys.exit(1)
    
    # --- Step 6: æ¸…ç† ---
    await shutdown()
    if os.path.exists(db_file):
        os.remove(db_file)
    logger.info("âœ¨ Test Finished Successfully.")

if __name__ == "__main__":
    asyncio.run(main())