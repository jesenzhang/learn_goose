import asyncio
import os
import sys

# --- å…³é”®è®¾ç½®ï¼šé€‚é… src ç›®å½•ç»“æ„ ---
# è¿™ä¸€æ­¥ç¡®ä¿å³ä½¿æ²¡æœ‰è¿è¡Œ 'pip install -e .' ä¹Ÿèƒ½æ‰¾åˆ° goose åŒ…
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

print(f"ğŸ“‚ Added source path: {src_path}")

# --- å¯¼å…¥æ¨¡å— (åŸºäºæœ€æ–°çš„ goose åŒ…ç»“æ„) ---
from goose.session import SessionManager
from goose.conversation import Message, Role, TextContent
from goose.model import ModelConfig
from goose.providers import OpenAIProvider

# --- é…ç½®åŒºåŸŸ (è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹) ---
# vLLM / Qwen / Ollama é…ç½®
API_BASE = "http://192.168.10.180:8088/v1/" 
API_KEY = "vllm"
# æ³¨æ„ï¼šæ¨¡å‹åç§°å¿…é¡»ä¸ vLLM å¯åŠ¨å‚æ•°æˆ– list_models è¿”å›çš„ä¸€è‡´
MODEL_NAME = "qwen3_vl" 

async def main():
    print("\nğŸš€ Starting Goose-Py LLM Integration Test (Src Layout)\n")

    # 1. åˆå§‹åŒ–æ•°æ®åº“ (SessionStorage)
    print("Step 1: Initializing Database...")
    # è¿™ä¼šè‡ªåŠ¨è¿è¡Œ migrations åˆ›å»ºè¡¨
    await SessionManager.get_storage()
    print("âœ… Database initialized.")

    # 2. åˆ›å»ºæ–°ä¼šè¯
    print("\nStep 2: Creating Session...")
    session = await SessionManager.create_session(name="Integration Test Session")
    print(f"âœ… Session Created: {session.id} (Type: {session.session_type})")

    # 3. æ„é€ å¹¶å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯
    user_query = "è¯·ç”¨ Python å†™ä¸€ä¸ª Hello Worldï¼Œå¹¶ç®€å•è§£é‡Šä¸€ä¸‹ã€‚"
    print(f"\nStep 3: User sends: '{user_query}'")
    
    user_msg = Message.user(user_query)
    await SessionManager.add_message(session.id, user_msg)
    print("âœ… User message saved to DB.")

    # 4. åˆå§‹åŒ–æ¨¡å‹æä¾›è€… (Provider)
    print(f"\nStep 4: Connecting to Provider ({MODEL_NAME})...")
    config = ModelConfig(
        model_name=MODEL_NAME, 
        temperature=0.7,
        max_tokens=1024
    )
    
    provider = OpenAIProvider(
        model_config=config,
        base_url=API_BASE,
        api_key=API_KEY
    )

    # 5. è·å–å†å²è®°å½• (ç”¨äºå‘é€ç»™ LLM)
    history = await SessionManager.get_messages(session.id)
    system_prompt = "You are a professional coding assistant named Goose."

    # 6. æµå¼è°ƒç”¨ LLM å¹¶å®æ—¶è¾“å‡º
    print("\nStep 5: Streaming Response...")
    print("-" * 50)
    
    full_response_text = ""
    token_usage = None

    try:
        async for msg, usage in provider.stream(system_prompt, history):
            # å¤„ç†æ–‡æœ¬å¢é‡
            if msg and msg.content:
                # æ³¨æ„ï¼šMessageContent åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ é€šå¸¸æ˜¯ TextContent
                content_item = msg.content[0]
                if isinstance(content_item, TextContent):
                    chunk = content_item.text
                    print(chunk, end="", flush=True)
                    full_response_text += chunk
            
            # å¤„ç† Token ç»Ÿè®¡ (é€šå¸¸åœ¨æœ€åè¿”å›)
            if usage:
                token_usage = usage
    except Exception as e:
        print(f"\nâŒ Error during streaming: {e}")
        # å¦‚æœæ˜¯è¿æ¥é”™è¯¯ï¼Œæ‰“å°æç¤º
        if "Connection" in str(e):
            print("Tip: Check if your vLLM server URL is correct and accessible.")
        await SessionManager.shutdown()
        return

    print("\n" + "-" * 50)

    # 7. å­˜å‚¨ AI å›å¤
    if full_response_text:
        print("\nStep 6: Saving Assistant Response...")
        ai_msg = Message.assistant(full_response_text)
        await SessionManager.add_message(session.id, ai_msg)
        print("âœ… AI response saved.")
    
    # 8. éªŒè¯ä¸ç»Ÿè®¡
    print("\nStep 7: Verification")
    if token_usage:
        print(f"ğŸ“Š Usage Stats: Input={token_usage.usage.input_tokens}, Output={token_usage.usage.output_tokens}")
    
    # éªŒè¯æ•°æ®åº“ä¸­çš„æ¶ˆæ¯æ•°é‡
    stored_msgs = await SessionManager.get_messages(session.id)
    print(f"ğŸ” Messages in DB: {len(stored_msgs)} (Expected >= 2)")
    
    # 9. æ¸…ç†èµ„æº
    await SessionManager.shutdown()
    print("\nğŸ‰ Test Completed Successfully!")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nTest interrupted by user.")